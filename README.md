# MoICE: Mixture of In-Context Experts ‚Äî –†–µ–ø—Ä–æ–¥—É–∫—Ü–∏—è –∏ —Ä–∞–∑–±–æ—Ä –ø—Ä–æ–±–ª–µ–º –∑–∞–ø—É—Å–∫–∞

–î–∞–Ω–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ä–∞–±–æ—Ç—ã  
**‚ÄúMixture of In-Context Experts Enhance LLMs‚Äô Long Context Awareness‚Äù (Lin et al., 2024)**  
—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ TinyLlama –∏ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è MoICE.

–ü–æ–º–∏–º–æ –±–∞–∑–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –ø–æ –∑–∞–ø—É—Å–∫—É –∑–¥–µ—Å—å **–ø–æ–¥—Ä–æ–±–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è, –ø–æ—á–µ–º—É —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –±—ã–ª –¥–æ–≤–µ–¥–µ–Ω –¥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ –∫–æ–Ω—Ü–∞**, –∏ –∫–∞–∫–∏–µ –ø–æ–¥—Ö–æ–¥—ã –±—ã–ª–∏ –∏—Å–ø—Ä–æ–±–æ–≤–∞–Ω—ã.

---

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –ê–ø–ø–∞—Ä–∞—Ç–Ω—ã–µ

- NVIDIA GPU —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA (–≤ —Ä–∞–±–æ—Ç–µ: RTX 4060)
- –î—Ä–∞–π–≤–µ—Ä NVIDIA, –≤–∫–ª—é—á–µ–Ω–Ω—ã–π passthrough –≤ WSL2
- –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –æ–±—ä–µ–º –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏: ‚â• 12 GB

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–µ

- –û–°: Linux –∏–ª–∏ WSL2 (–≤ —Ä–∞–±–æ—Ç–µ: Ubuntu –ø–æ–¥ WSL2)
- Python 3.10
- Conda / Miniconda
- PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA

---

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å:

```bash
conda create -n moice python=3.10 -y
conda activate moice

# PyTorch —Å CUDA 11.8
pip install torch==2.1.2+cu118 --index-url https://download.pytorch.org/whl/cu118

# –ë–∞–∑–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è MoICE
pip install transformers==4.33.2
pip install accelerate==0.22.0
pip install deepspeed==0.10.3
pip install sentencepiece protobuf
```

> FlashAttention –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –∏ –≤ WSL2, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –Ω–µ —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –±–µ–∑ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ CUDA Toolkit –∏ `nvcc`.

---

## –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ TinyLlama

### –ß–µ—Ä–µ–∑ CLI `huggingface-hub`

```bash
pip install huggingface_hub==0.19.3

huggingface-cli download   TinyLlama/TinyLlama-1.1B-Chat-v1.0   --local-dir models/llama2-7b-chat
```

---

## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–ª–æ—Å—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **PG-19** (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–µ). –ò–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –¥–∞–Ω–Ω—ã–º –∏ `git-lfs` –ø–æ–¥ WSL2 –±—ã–ª –≤—ã–±—Ä–∞–Ω –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –Ω–∞–±–æ—Ä ‚Äî **Refined BookCorpus** —Å Kaggle.

–§–∞–π–ª CSV –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–ª—Å—è –≤ JSON-—Ñ–æ—Ä–º–∞—Ç, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å –æ–∂–∏–¥–∞–Ω–∏—è–º–∏ `train-balance.py`:

```bash
python tools/convert_csv_to_json.py   --input path/to/bookcorpus.csv   --train-output data/train_data.json   --eval-output data/eval_data.json
```

---

## –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏

–ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –æ–±—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è:

```bash
python - << 'EOF'
from transformers import AutoTokenizer, AutoModelForCausalLM

model_path = "models/llama2-7b-chat"

tok = AutoTokenizer.from_pretrained(model_path)
print("tokenizer ok:", tok.__class__.__name__)

model = AutoModelForCausalLM.from_pretrained(model_path)
print("model ok, params:", sum(p.numel() for p in model.parameters())/1e6, "M")
EOF
```

–ù–∞ –æ–¥–Ω–æ–º –∏–∑ —ç—Ç–∞–ø–æ–≤ —Ä–∞–±–æ—Ç—ã –≤—ã—è—Å–Ω–∏–ª–æ—Å—å, —á—Ç–æ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ —Å–∫–∞—á–∞–Ω–Ω—ã–π `pytorch_model.bin` –±—ã–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏–ª–æ –∫ –æ—à–∏–±–∫–µ:

```text
_pickle.UnpicklingError: Unsupported operand 149
```

–ü–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –≤–µ—Å–æ–≤ –ø—Ä–æ–±–ª–µ–º–∞ –±—ã–ª–∞ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∞.

---

## –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

### –°–∫—Ä–∏–ø—Ç (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è)

```bash
cd training
bash train.sh
```

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç DeepSpeed —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–ø—Ä–∏–º–µ—Ä):

```bash
deepspeed --num_gpus=4 train-balance.py   --model_name_or_path ../models/llama2-7b-chat   --data_path ../data/train_data.json   --eval_data_path ../data/eval_data.json   ...
```

### –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π-—Å–∫—Ä–∏–ø—Ç

–î–ª—è WSL2 + RTX 4060 –±—ã–ª –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç `train2.sh`, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–∑—ã–≤–∞–µ—Ç `train-balance.py` –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ DeepSpeed), —Å —Ç–µ–º–∏ –∂–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –º–æ–¥–µ–ª–∏ –∏ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –≤ —Ä–µ–∂–∏–º–µ –æ–¥–Ω–æ–≥–æ GPU.

---

## –ü–æ—á–µ–º—É –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –±—ã–ª –¥–æ–≤–µ–¥–µ–Ω –¥–æ –∫–æ–Ω—Ü–∞

–ù–∏–∂–µ ‚Äî –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–±–æ—Ä **–≤—Å–µ—Ö –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π**, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ —Å—Ç–æ–ª–∫–Ω—É–ª—Å—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç, –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –∏ –ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ.

### 1. –°—Ç–∞—Ä—Ç –Ω–∞ Windows + conda –∏ –ø–µ—Ä–µ—Ö–æ–¥ –≤ WSL

–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å–∫–∞ –≤–µ–ª–∞—Å—å –≤ —Å—Ä–µ–¥–µ Windows (PowerShell) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º `conda` / `miniconda`. –£–∂–µ –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –Ω–∞—á–∞–ª–∏ –ø—Ä–æ—è–≤–ª—è—Ç—å—Å—è –ø—Ä–æ–±–ª–µ–º—ã:

- –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ `conda` –¥–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ `conda init`;
- —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π `bitsandbytes` –ø–æ–¥ Windows (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ Linux);
- –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –∫–æ—Å—Ç—ã–ª–µ–π –≤–∏–¥–∞ `bitsandbytes-windows` –∏ —Ä—É—á–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥—É–ª–µ–π.

–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –±—ã–ª–æ –ø—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –≤ WSL2 (Ubuntu), –≥–¥–µ —Å—Ç–µ–∫ PyTorch + CUDA –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –±–æ–ª–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ.

---

### 2. –î–æ—Å—Ç—É–ø –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º (PG-19, Google Cloud, git-lfs, Kaggle)

–ë—ã–ª–∞ –ø—Ä–µ–¥–ø—Ä–∏–Ω—è—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:

- **PG-19** (DeepMind) —á–µ—Ä–µ–∑ Google Cloud Storage;
- –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π PG-19 —á–µ—Ä–µ–∑ `git lfs`.

–í–æ–∑–Ω–∏–∫–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã:

- `git lfs` –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞–±–æ—Ç–∞–ª/–Ω–µ –±—ã–ª —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ WSL2;
- —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ GCS —Ç—Ä–µ–±–æ–≤–∞–ª–æ –¥–æ–ø. –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Å–∫—Ä–∏–ø—Ç–æ–≤.

–î–∞–ª–µ–µ –±—ã–ª —Å–¥–µ–ª–∞–Ω –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ Kaggle:

- –ø–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `kaggle datasets download` –Ω–∞—Ç–∫–Ω—É–ª–∞—Å—å –Ω–∞ `403 Forbidden` (–ø—Ä–æ–±–ª–µ–º—ã —Å API-—Ç–æ–∫–µ–Ω–æ–º / –ø—Ä–∞–≤–∞–º–∏);
- –≤ –∏—Ç–æ–≥–µ –¥–∞—Ç–∞—Å–µ—Ç –±—ã–ª —Å–∫–∞—á–∞–Ω –≤—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Kaggle (Refined BookCorpus) –∏ –∑–∞—Ç–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.

–í—ã–≤–æ–¥: **–¥–∞–Ω–Ω—ã–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å**, —ç—Ç–æ—Ç —ç—Ç–∞–ø, –ø–æ —Å—É—Ç–∏, –Ω–µ —Å—Ç–∞–ª –±–ª–æ–∫–∏—Ä—É—é—â–∏–º, –Ω–æ –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.

---

### 3. –í–µ—Ä—Å–∏–æ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã: Transformers ‚Üî Huggingface Hub ‚Üî Accelerate

–ù–∞ –æ–¥–Ω–æ–º –∏–∑ —ç—Ç–∞–ø–æ–≤, –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏/–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫, –≤–æ–∑–Ω–∏–∫–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å:

```text
ImportError: huggingface-hub>=0.19.3,<1.0 is required for a normal functioning of this module, but found huggingface-hub==1.1.6.
```

–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ:

- `accelerate` —Ç—Ä–µ–±–æ–≤–∞–ª –Ω–æ–≤—ã—Ö API –∏–∑ `huggingface_hub`;
- –±–æ–ª–µ–µ —Å–≤–µ–∂–∏–π `accelerate` –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞–ª —Å –≤–µ—Ä—Å–∏–µ–π Transformers, –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –æ–ø–∏—Ä–∞–µ—Ç—Å—è MoICE;
- —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ `accelerate` –Ω–µ –¥—Ä—É–∂–∏–ª–∏ —Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–º PyTorch 2.1+.

–ü–æ —Å—É—Ç–∏, —Ç—Ä–µ–±–æ–≤–∞–ª–∞—Å—å –æ—á–µ–Ω—å —Ç–æ—á–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –≤–µ—Ä—Å–∏–π:
- Transformers –ø—Ä–∏–º–µ—Ä–Ω–æ 4.33‚Äì4.35,
- huggingface-hub < 1.0,
- accelerate –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ ~0.21‚Äì0.22,
- PyTorch –Ω–µ –Ω–∏–∂–µ 1.13, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º –Ω–æ–≤—ã–π.

–ü–æ–¥–æ–±—Ä–∞—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω—É—é —Ç—Ä–æ–π–∫—É ¬´Transformers + Accelerate + Huggingface Hub¬ª –Ω–∞ –≥–æ—Ç–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ —Å —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ –æ–∫–∞–∑–∞–ª–æ—Å—å –Ω–µ—Ç—Ä–∏–≤–∏–∞–ª—å–Ω–æ.

---

### 4. BitsAndBytes –∏ PyTorch 2.x

–ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ `bitsandbytes` –¥–ª—è 8-–±–∏—Ç–Ω—ã—Ö –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞:

```text
AttributeError: module 'torch.library' has no attribute 'impl_abstract'
```

–û–Ω–∞ —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤—É–µ—Ç –æ —Ç–æ–º, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è `bitsandbytes` –Ω–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å PyTorch 2.1+ (–æ–∂–∏–¥–∞–µ—Ç—Å—è –±–æ–ª–µ–µ —Å—Ç–∞—Ä—ã–π API).  
–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è `bitsandbytes` —Å—Ç–∞–ª–æ —è—Å–Ω–æ, —á—Ç–æ –¥–ª—è —Ü–µ–ª–µ–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ 8-–±–∏—Ç–Ω–∞—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π, –∏ –µ–µ –º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å. –û–¥–Ω–∞–∫–æ —Å–∞–º —Ñ–∞–∫—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –≥–æ–≤–æ—Ä–∏—Ç –æ —Ö—Ä—É–ø–∫–æ—Å—Ç–∏ —Å–≤—è–∑–∫–∏ MoICE —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º —Å—Ç—ç–∫–æ–º.

---

### 5. FlashAttention –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ CUDA Toolkit (`nvcc`) –≤ WSL2

–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π `requirements.txt` MoICE –≤–∫–ª—é—á–∞–µ—Ç:

```text
flash-attn==2.3.2
```

–ü–æ–ø—ã—Ç–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏:

```bash
pip install flash-attn==2.3.2
# –∏–ª–∏
pip install flash-attn==2.5.6 --no-build-isolation
```

–∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –æ—à–∏–±–∫–æ–π:

```text
OSError: CUDA_HOME environment variable is not set. nvcc was not found.
```

–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:

- –≤ WSL2 –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ GPU (—á–µ—Ä–µ–∑ –¥—Ä–∞–π–≤–µ—Ä—ã –∏ CUDA runtime),
- **–Ω–æ –Ω–µ—Ç –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ CUDA Toolkit** –∏ –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä–∞ `nvcc`,
- flash-attn —Ç—Ä–µ–±—É–µ—Ç –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ CUDA-—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π –∏ –±–µ–∑ —ç—Ç–æ–≥–æ –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è.

–§–∞–∫—Ç–∏—á–µ—Å–∫–∏, –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è FlashAttention –≤ —Ç–∞–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ CUDA Toolkit –≤–Ω—É—Ç—Ä—å WSL2, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É—Å–ª–æ–∂–Ω—è–µ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ.

---

### 6. –ü—Ä–æ–±–ª–µ–º—ã —Å `requirements.txt` MoICE

–ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —á–µ—Å—Ç–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ –∏–∑ `requirements.txt`:

```bash
pip install -r requirements.txt
```

–≤–æ–∑–Ω–∏–∫–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º:

1. –ü–∞–∫–µ—Ç `dataset==0.1.3` ‚Äî –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –≤–µ—Ä—Å–∏—è (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –æ–ø–µ—á–∞—Ç–∫–∞ –≤–º–µ—Å—Ç–æ `datasets` –æ—Ç Hugging Face).
2. –ñ–µ—Å—Ç–∫–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è `flash-attn==2.3.2`, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ —Å—Ç–∞–≤–∏—Ç—Å—è –±–µ–∑ CUDA Toolkit.
3. –ò—Ç–æ–≥–æ–º —Å—Ç–∞–Ω–æ–≤–∏–ª–∞—Å—å —á–∞—Å—Ç–∏—á–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Å—Ä–µ–¥–∞ –±–µ–∑ –∫–ª—é—á–µ–≤—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ (`transformers` –∏ –¥—Ä.), —Ç–∞–∫ –∫–∞–∫ –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä—ã–≤–∞–ª—Å—è –Ω–∞ –æ—à–∏–±–∫–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ flash-attn.

–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –±—ã–ª–æ –ø—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ **–Ω–µ –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞ `requirements.txt`** –∏ —Å–æ–±–∏—Ä–∞—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ –≤—Ä—É—á–Ω—É—é, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫.

---

### 7. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è MoICE –≤ LLaMA –∏ —Ä—É—á–Ω–æ–π –ø–∞—Ç—á–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

–î–∞–∂–µ –ø–æ—Å–ª–µ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Ä—Å–∏–π –∏ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ TinyLlama –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ `modeling_llama.py` –¥–ª—è MoICE –≤–æ–∑–Ω–∏–∫–ª–∏ –æ—à–∏–±–∫–∏:

- –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ–ª—è `base_set`, `topk`, `expert_nums` –≤ `LlamaConfig`;
- –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã gate-—Å–ª–æ–µ–≤ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —á–µ–∫–ø–æ–π–Ω—Ç–æ–º.

–≠—Ç–æ –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª–æ **—Ä—É—á–Ω–æ–≥–æ –ø–∞—Ç—á–∏–Ω–≥–∞**:

```python
config.base_set = [10000, 17500, 18000, 19000, 20000, 22500, 25000]
config.topk = 7
config.expert_nums = 7
config.output_router_logits = True
config.router_aux_loss_coef = 0.3
```

–ø–æ—Å–ª–µ —á–µ–≥–æ –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∞—Å—å, –Ω–æ —É–∂–µ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º –æ —Ç–æ–º, —á—Ç–æ –Ω–æ–≤—ã–µ —Å–ª–æ–∏ (gates) –∏–º–µ—é—Ç —Å–ª—É—á–∞–π–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –∏ —Ç—Ä–µ–±—É—é—Ç –¥–æ–æ–±—É—á–µ–Ω–∏—è.

---

### 8. –ò—Ç–æ–≥–æ–≤–∞—è —Ç–æ—á–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏

–ù–∞ –º–æ–º–µ–Ω—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–ø—É—Å–∫ `train2.sh` —É–ø–∏—Ä–∞–ª—Å—è –≤ —Ü–µ–ø–æ—á–∫—É –≤–µ—Ä—Å–∏–æ–Ω–Ω—ã—Ö –∏ –±–∏–Ω–∞—Ä–Ω—ã—Ö –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤:

- –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–æ–¥–≥–æ–Ω—è—Ç—å –≤–µ—Ä—Å–∏–∏ Transformers, Accelerate –∏ Huggingface Hub;
- –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∫–∏ FlashAttention –±–µ–∑ CUDA Toolkit;
- —Å–∏–ª—å–Ω–æ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∏ —á–∞—Å—Ç–∏—á–Ω–æ —É—Å—Ç–∞—Ä–µ–≤—à–∏–π `requirements.txt`, –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—â–∏–π—Å—è –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ.

–ü—Ä–∏ —ç—Ç–æ–º:

- –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è,
- –¥–∞—Ç–∞—Å–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω.

**–û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫–∏—Ä—É—é—â–∏–π —Ñ–∞–∫—Ç–æ—Ä** ‚Äî —Ö—Ä—É–ø–∫–æ—Å—Ç—å —Å–≤—è–∑–∫–∏ ¬´MoICE + —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ HuggingFace-—Å—Ç–µ–∫–∞ + FlashAttention¬ª –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å—Ä–µ–¥–µ (PyTorch 2.1, WSL2 –±–µ–∑ CUDA Toolkit, —Å–≤–µ–∂–∏–µ –≤–µ—Ä—Å–∏–∏ huggingface_hub).

---

## üß© –í—ã–≤–æ–¥—ã

1. **MoICE –≤ —Ç–µ–∫—É—â–µ–º –≤–∏–¥–µ –ø–ª–æ—Ö–æ –ø–µ—Ä–µ–Ω–æ—Å–∏–º** –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è; –æ–Ω —Ä–∞—Å—Å—á–∏—Ç–∞–Ω –Ω–∞ –¥–æ–≤–æ–ª—å–Ω–æ —É–∑–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –≤–µ—Ä—Å–∏–π –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏, –≤–æ–∑–º–æ–∂–Ω–æ, —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞–≤—Ç–æ—Ä–æ–≤.
2. –ü–æ–ª–Ω—ã–π –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Ç—Ä–µ–±—É–µ—Ç:
   - –ª–∏–±–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è Docker/–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏,
   - –ª–∏–±–æ —Å—Ç—Ä–æ–≥–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–æ–≤ (–≤–∫–ª—é—á–∞—è CUDA Toolkit).
3. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç—å –∑–∞–ø—É—Å–∫–∞, –±—ã–ª–∞ –ø—Ä–æ–¥–µ–ª–∞–Ω–∞ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞:
   - –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç,
   - –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å TinyLlama,
   - –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω—ã MoICE-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã,
   - –≤—ã—è–≤–ª–µ–Ω—ã –∏ –∑–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–µ —Ç–æ—á–∫–∏.

---

## üìñ –°–≤—è–∑–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã

- –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç—å—è: https://arxiv.org/abs/2405.02765  
- –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π MoICE: https://github.com/Exploration-Lab/MoICE  
- TinyLlama –º–æ–¥–µ–ª—å: https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0

